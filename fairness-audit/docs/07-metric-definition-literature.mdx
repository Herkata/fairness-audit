---
title: Metric Definition Literature
sidebar_position: 7
slug: /metric-definition-literature
---

# Metric Definition Literature

Reference catalog of group, individual, and multi-dimensional fairness metrics with goals, focuses, equations, and trade-offs.

> Need a guided selection workflow? Use the [Comprehensive Metrics Tool](/docs/comprehensive-metrics).

## **1 Group Fairness Metrics**

### 1.1 Statistical Parity (Demographic Parity)

**Goal:** Equal rate of positive predictions across demographic groups.

**Focus:** Outcome distribution.

**Definition:**

$$
P(\hat{Y} = 1 \mid A = a) = P(\hat{Y} = 1 \mid A = b)
$$

**Metric:**

Statistical Parity Difference (SPD)

$$
\text{SPD} = \big| P(\hat{Y} = 1 \mid A = a) - P(\hat{Y} = 1 \mid A = b) \big|
$$

**Best For:** Contexts where equal representation in outcomes is the primary objective (e.g., shortlisting, resource allocation).

**Trade-Off:** May conflict with accuracy and qualification differences when base rates vary.

**Analogy:** Like admissions targets that ensure equal admit rates across groups, focusing on outcome distribution over individual merit.

---

### 1.2 Equal Opportunity (True Positive Rate Parity)

**Goal:** Equal chance for qualified individuals to receive positive predictions.

**Focus:** Recall (True Positive Rate).

**Definition:**

$$
P(\hat{Y} = 1 \mid Y = 1, A = a) = P(\hat{Y} = 1 \mid Y = 1, A = b)
$$

**Metric:**

Equal Opportunity Difference (EOD)

$$
\text{EOD} = \big| \text{TPR}_a - \text{TPR}_b \big|
$$

**Best For:** Merit-based systems (lending, hiring, admissions).

**Trade-Off:** Does not control false positive disparities.

**Analogy:** Like a hiring rule ensuring equally qualified candidates get equal interview chances across groups.

---

### 1.3 Equalized Odds (Error Rate Balance)

**Goal:** Equal true positive and false positive rates across groups.

**Focus:** Full error rate balance.

**Definition:**

$$
P(\hat{Y} = 1 \mid Y = y, A = a) = P(\hat{Y} = 1 \mid Y = y, A = b),\quad y \in \{0, 1\}
$$

**Metrics:**

- TPR Difference
- FPR Difference

**Best For:** High-stakes decisions (criminal justice, medical diagnosis, fraud detection).

**Trade-Off:** Stronger constraint; may reduce accuracy.

**Analogy:** Like airport screening that equalizes both false alarms and misses across groups.

---

### 1.4 Predictive Parity (Positive Predictive Value Parity)

**Goal:** Equal precision of positive predictions across groups.

**Focus:** Reliability of predictions.

**Definition:**

$$
P(Y = 1 \mid \hat{Y} = 1, A = a) = P(Y = 1 \mid \hat{Y} = 1, A = b)
$$

**Metric:**

Predictive Parity Difference (PPD)

$$
\text{PPD} = \big| \text{PPV}_a - \text{PPV}_b \big|
$$

**Best For:** Risk scoring systems (credit scoring, medical risk assessment).

**Trade-Off:** Cannot be simultaneously satisfied with equalized odds when base rates differ.

**Analogy:** Like ensuring a medical testâ€™s positive result is equally trustworthy for all groups.

## **2 Individual Fairness Metrics**

### 2.1 Similarity-Based Fairness (Individual Fairness)

**Goal:** Similar individuals should receive similar outcomes.

**Focus:** Individual-level consistency.

**Definition (Dwork et al., 2012):**

$$
d_Y(f(x_i), f(x_j)) \le L \cdot d_X(x_i, x_j)
$$

**Core Idea:** Outcome differences must be justified by relevant feature differences.

**Best For:** Lending, admissions, hiring.

**Trade-Off:** Requires defining a valid similarity metric (subjective and domain-specific).

---

### 2.2 Task-Specific Similarity Metrics

**Goal:** Define what "similar" means for a specific domain.

**Focus:** Relevant feature selection and weighting.

**Core Principle:** Similarity must reflect legitimate decision factors while excluding proxies for protected attributes.

**Best For:** Domain-sensitive systems (credit scoring, hiring, admissions).

**Trade-Off:** Normative judgments shape fairness outcomes.

---

### 2.3 Fairness Through Awareness (FTA)

**Goal:** Achieve fairness by explicitly considering protected attributes.

**Focus:** Informed, context-aware similarity.

**Core Principle:** Protected attributes should not be ignored if they influence how achievements are interpreted.

**Best For:** Contexts involving structural inequality (education, hiring).

**Trade-Off:** Requires careful justification of how protected attributes inform fairness adjustments.

---

### 2.4 Counterfactual Fairness

**Goal:** Ensure predictions remain the same if a protected attribute were different.

**Focus:** Causal individual fairness.

**Best For:** High-stakes decisions (lending, admissions, criminal justice).

**Trade-Off:** Requires building and validating a causal model.

## **3 Multi-Dimensional Fairness Metrics**

### 3.1 Multi-Attribute Error Rate Balance

**Goal:** Equalize error rates across all combinations of protected attributes.

**Focus:** Intersectional TPR and FPR parity.

**Definition:**

$$
P(\hat{Y} = 1 \mid Y = y, A_1 = a_1, A_2 = a_2, \dots)
$$

should be equal across all subgroup combinations for $y \in \{0,1\}$.

**Metrics:**

- Intersectional TPR Difference
- Intersectional FPR Difference
- Worst-Group Error Gap

**Trade-Off:** Small subgroup sizes may produce unstable estimates; requires strong statistical validation.

---

### 3.2 Intersectional Demographic Parity

**Goal:** Equalize positive prediction rates across all intersectional subgroups.

**Focus:** Outcome distribution fairness at intersections.

**Definition:**

$$
P(\hat{Y} = 1 \mid A_1 = a_1, A_2 = a_2, \dots)
$$

**Metric:** Intersectional Statistical Parity Difference (max gap between any two intersectional groups).

**Trade-Off:** May conflict with qualification differences across intersections.

---

### 3.3 Multi-Dimensional Subgroup Fairness

**Goal:** Protect the worst-off subgroup among all possible attribute combinations.

**Focus:** Worst-case disparity detection.

**Definition:**

$$
\max_{\text{subgroup}} \big|\text{disparity}\big|
$$

**Trade-Off:** Computationally intensive; needs thresholds and minimum sample safeguards.
